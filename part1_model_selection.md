Goal:
We want to detect AI-generated human speech (deepfakes), possibly in real-time, during real conversations.
We looked at 3 strong models for this task:

ðŸ”¹ 1. Wav2Vec2.0
What it is:

A powerful model from Facebook that learns directly from raw audio (no need for spectrograms or MFCCs).

Pretrained on a lot of speech, so it already understands audio well.

Why itâ€™s good:

Works with raw waveforms (less pre-processing).

Already trained on speech â€” we just need to fine-tune it.

Good for real-time use.

Results:

Very low error rate (EER around 1â€“3%) when fine-tuned.

Limitations:

Needs a classifier on top to make decisions (e.g., spoof or bonafide).

Can be heavy on memory.

ðŸ”¹ 2. RawNet2
What it is:

A model designed specifically for detecting fake audio.

Uses CNN and GRU (a type of RNN) to understand patterns in raw waveforms.

Why itâ€™s good:

Built for spoof detection.

No need to convert audio to spectrograms.

Top performer in many audio deepfake competitions.

Results:

Error rate (EER) is ~1â€“2%, very strong.

Limitations:

Training from scratch takes time and resources.

Slightly bigger model, might not be ideal for real-time unless optimized.

ðŸ”¹ 3. LCNN (Lightweight CNN)
What it is:

A smaller, faster CNN model that uses spectrograms as input.

Often used as a simple baseline for spoof detection.

Why itâ€™s good:

Lightweight and fast â€” works on low-power devices.

Easy to train and modify.

Results:

EER between 4â€“6%, decent for small models.

Limitations:

Needs spectrograms â€” extra step before training.

Doesnâ€™t learn long-term patterns as well as others.
